{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## load dependencies\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "import torch \n",
    "import random\n",
    "import importlib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import casadi\n",
    "from math import sqrt\n",
    "import torch.nn as nn\n",
    "from sklearn.svm import SVR \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Hand made classes\n",
    "from src import DataPreprocessing as dp\n",
    "from src import Model_PINN_casadi as pinn_casadi\n",
    "from src import plotter\n",
    "\n",
    "# Organize this\n",
    "device = torch.device(\"cpu\")\n",
    "torch.manual_seed(4)\n",
    "np.random.seed(4) \n",
    "random.seed(4)\n",
    "\n",
    "#        [  0    ,   1      ,     2      ,     3   ,    4     ,   5    ,   6   ,    7     ,     8     ,  9    ,   10    ,  11 , 12  ,  13   ,  14 ,  15     , 16 ]\n",
    "output = ['O2(X)','O2(a1Dg)', 'O2(b1Sg+)','O2(Hz)','O2(+,X)', 'O(3P)','O(1D)','O(+,gnd)', 'O(-,gnd)','O3(X)','O3(exc)', 'Tg','Tnw','Red_E', 'vd', 'E_mean','ne']\n",
    "\n",
    "input = ['P','I', 'R']\n",
    "fraction_train = 0.8\n",
    "fraction_test = 0.1\n",
    "fraction_val = 0.1\n",
    "runLR = 0\n",
    "runSamplingComparison = 1\n",
    "runNN = 1\n",
    "runSA = 1\n",
    "apply_kfolds = 1\n",
    "optimize_svr = 0\n",
    "apply_PCA = 0\n",
    "apply_LHS = 0\n",
    "apply_PAS = 0\n",
    "apply_grid_search = 0\n",
    "apply_EDA = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **1. Data Visualization & Pre-Processing**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "   ## **1.1. Import data from .txt file and visualize it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dp)\n",
    "importlib.reload(plotter)\n",
    "\n",
    "# Define the filename\n",
    "filename_initial = '/Users/matildevalente/Documents/PINN_Paper/LTP_System/Datasets/Morris/p10/3input_1000.txt'\n",
    "delimiter= ' '\n",
    "\n",
    "# Extract Data From File\n",
    "full_dataset = dp.LoadDataset(filename_initial)\n",
    "y_data = full_dataset.y\n",
    "X_data = full_dataset.x\n",
    "df = pd.read_csv(filename_initial, delimiter= delimiter, header=None, names= input + output)\n",
    "\n",
    "# Plot histogram to visualize the inputs\n",
    "num_bins = 10\n",
    "num_bins, min_I, max_I, col_name, x_label, title = 50, 0, 0.055, \"I\", 'Values in Column I', 'Histogram of Column I'\n",
    "\n",
    "hist, bin_edges = plotter.Histogram_3inputs(df, min_I, max_I, num_bins, col_name, x_label, title)\n",
    "\n",
    "# Example usage with dummy data\n",
    "plotter.plot_pie_chart_species_densities(y_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.2. Preprocess data: min max scaling and log-transform**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA DEFINITION  ------------------------------------------------------------------------------------------\n",
    "# Initialize Plots and define loss func\n",
    "importlib.reload(dp)\n",
    "importlib.reload(plotter)\n",
    "\n",
    "# Define Threshold\n",
    "skew_threshold_up = 3\n",
    "skew_threshold_down = 0#0.09\n",
    "\n",
    "# Create data_prepocessed object\n",
    "path = '/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/Histograms/'\n",
    "data_prepocessed = dp.DataPreprocessor(output, input, fraction_train, fraction_val, skew_threshold_down, skew_threshold_up)\n",
    "data_prepocessed.setup_dataset(X_data, y_data, apply_EDA, path)\n",
    "data_prepocessed_copy = copy.deepcopy(data_prepocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **1.3. Visualize the amplitute of different input and output features**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plotter)\n",
    "plotter.plot_feature_amplitutes(y_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **2. Implement Data-Driven NN Model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.1. Define the Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT RUN\n",
    "importlib.reload(pinn_casadi)\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# NEURAL NETWORK  ---------------------------------------------------------------------------------------------------------------------------------\n",
    "# 1. Define Hyperparameters\n",
    "print_flag = 1\n",
    "show_plots = 0\n",
    "batch_size = 10\n",
    "lrn_rate = 0.0001\n",
    "epoch_window = 50\n",
    "max_epochs = 500\n",
    "ep_log_interval = 1\n",
    "training_threshold=0.0000001\n",
    "loss_func, loss_func_data, loss_func_physics = torch.nn.MSELoss(), torch.nn.MSELoss(), torch.nn.MSELoss()\n",
    "\n",
    "#PINN parameters - L_1: pressure; L_2: current; L_3: zero charge - relative weigth \n",
    "lambda_physics = [0, 0, 0]      \n",
    "\n",
    "# Activation Functions to search from\n",
    "activation_functions = [F.leaky_relu] #[F.leaky_relu, F.relu, F.tanh, F.sigmoid]\n",
    "\n",
    "# Base architecture & Number of architectures to generate\n",
    "base_architecture = [10, 10,10]\n",
    "num_architectures = 75\n",
    "\n",
    "# Get the best architecture\n",
    "W = np.eye(len(data_prepocessed.output))\n",
    "model = (pinn_casadi.PhysicsAwareNet(base_architecture, lrn_rate , batch_size, 0, lambda_physics, activation_functions, W).to(device)).to(torch.double) \n",
    "data_prepocessed_copy = copy.deepcopy(data_prepocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.2. Determine the Optimal Architecture Using Random Search**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#min_val_loss_row = model.getArchitecture(data_prepocessed_copy, num_architectures, base_architecture, ep_log_interval, loss_func_data, loss_func_physics, training_threshold, max_epochs, epoch_window, show_plots)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Best Architecture: \", min_val_loss_row['architecture'])\n",
    "#print(\"Activation Functions: \", min_val_loss_row['activ_func'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.3. Train the model with the chosen architecture**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pinn_casadi)\n",
    "importlib.reload(dp)\n",
    "importlib.reload(plotter)\n",
    "import torch.nn.functional as F\n",
    "\n",
    "print_flag = 0\n",
    "\n",
    "# 1. Define Hyperparameters\n",
    "max_epochs =  500\n",
    "hidden_size_arr = [451, 315, 498, 262] #min_val_loss_row['architecture'] \n",
    "activation_func = [F.leaky_relu,F.leaky_relu,F.leaky_relu,F.leaky_relu] #min_val_loss_row['activ_func']\n",
    "\n",
    "# number of models in the bootstrap aggregation algorithm\n",
    "num_models = 50  \n",
    "\n",
    "# 2. Train Model\n",
    "myplot_nn = pinn_casadi.MyPlots()\n",
    "data_prepocessed_copy = copy.deepcopy(data_prepocessed)\n",
    "val_loader = torch.utils.data.DataLoader(data_prepocessed_copy.val_data, batch_size=batch_size, shuffle=True) # set to True\n",
    "nn_models, epoch_loss_arr_train, epoch_loss_arr_val, best_seed_pinn, epoch_loss_train_physics_sanity  = pinn_casadi.getTrainedPinns(val_loader,data_prepocessed_copy, num_models, hidden_size_arr, lrn_rate, batch_size, 0, lambda_physics, activation_func, epoch_window,print_flag, ep_log_interval, myplot_nn, loss_func_data, loss_func_physics, training_threshold, max_epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Plot Loss Curve\n",
    "importlib.reload(plotter)\n",
    "\n",
    "path = '/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/model_training_loss_curves/'\n",
    "plotter.LossCurvePlotNN(myplot_nn, path, \" \", num_models)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2.4. See Performance of NN and Compare it to Projection-Based PINN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pinn_casadi)\n",
    "importlib.reload(plotter)\n",
    "\n",
    "# 1. Path that contains experimental dataset\n",
    "file_name = \"/Users/matildevalente/Documents/PINN_Paper/LTP_System/Datasets/Morris/p10/3input_300.txt\"\n",
    "\n",
    "# 2. Path where the plots are to be stored\n",
    "save_path = \"/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/bar_plot_NN/\"\n",
    "\n",
    "# 3. Get results for identity matrix\n",
    "model_name = \"NN\"\n",
    "rse_pinn_3_laws, sem_pinn_3_laws, rse_nn, sem_nn = plotter.get_plot_W_matrix(torch.eye(17), file_name, data_prepocessed, nn_models, num_models, model_name, num_bars = 8, path = save_path)    \n",
    "plotter.get_plot_W_matrix(torch.eye(17), file_name, data_prepocessed, nn_models, num_models, model_name, num_bars = 5, path = save_path)    \n",
    "plotter.get_plot_W_matrix(torch.eye(17), file_name, data_prepocessed, nn_models, num_models, model_name, num_bars = 2, path = save_path)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **3. Train the loss based PINN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.1. Determine the optimal lambda parameter**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pinn_casadi)\n",
    "\n",
    "myplot_standard_PINN = pinn_casadi.MyPlots()\n",
    "num_pinns_lambda_optimization = 1\n",
    "max_epochs_lambda_optimization = 60\n",
    "print_flag = 0\n",
    "num_iterations = 1\n",
    "best_lambda_physics, list_val_losses, list_lambdas = pinn_casadi.optimize_lambda_physics(num_pinns_lambda_optimization, max_epochs_lambda_optimization, base_architecture, lrn_rate, batch_size, activation_functions, W, data_prepocessed_copy, hidden_size_arr, activation_func, epoch_window, print_flag, ep_log_interval, myplot_nn, loss_func_data, loss_func_physics, training_threshold, num_iterations)\n",
    "\n",
    "# Create a DataFrame\n",
    "df_lambda_optimization = pd.DataFrame(list_lambdas, columns=['lambda_physics_1', 'lambda_physics_2', 'lambda_physics_3'])\n",
    "df_lambda_optimization['lambda_data'] = 1 - (df_lambda_optimization['lambda_physics_1'] + df_lambda_optimization['lambda_physics_2'] + df_lambda_optimization['lambda_physics_2'])\n",
    "df_lambda_optimization['val_loss'] = list_val_losses\n",
    "\n",
    "# Save dataframe to computer in a CSV file\n",
    "full_path = \"/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/lambda_optimization/lambda_optimization.csv\"\n",
    "df_lambda_optimization.to_csv(full_path, index=False)\n",
    "df_lambda_optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2. Train the loss based PINN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lrn_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pinn_casadi)\n",
    "import torch.nn.functional as F\n",
    "importlib.reload(dp)\n",
    "importlib.reload(plotter)\n",
    "import itertools\n",
    "\n",
    "# NEURAL NETWORK  ---------------------------------------------------------------------------------------------------------------------------------\n",
    "#PINN parameters\n",
    "#print(\"Best lambda = \", best_lambda_physics)\n",
    "#lambda_physics =  [] #best_lambda_physics    # [0.01036426, 0.53862728, 0.00301796] [0.03063382, 0.51784745, 0.0035539 ] # # L_1: pressure; L_2: current; L_3: zero charge - relative weigth \n",
    "\n",
    "\n",
    "def generate_lambda_physics_values(N, options):\n",
    "        \n",
    "    # Generate all possible combinations of the remaining values\n",
    "    all_combinations = list(itertools.product(options, repeat=3))\n",
    "    \n",
    "    # Filter combinations to ensure the sum is less than 1\n",
    "    valid_sublists = [\n",
    "        [comb[0], comb[1], comb[2]] \n",
    "        for comb in all_combinations \n",
    "        if comb[0] + comb[1] + comb[2] < 1\n",
    "    ]\n",
    "    \n",
    "    # Return only the first N sublists\n",
    "    return valid_sublists\n",
    "\n",
    "\n",
    "# Example predetermined set of options\n",
    "options = np.linspace(0, 0.999, 10)\n",
    "options = np.logspace(np.log(0.0001), 0, 10)\n",
    "N = len(list(itertools.product(options, repeat=3)))\n",
    "print(options)\n",
    "\n",
    "# Generate a random list of lists with 4 sublists, each of length 4\n",
    "lambda_physics_list = generate_lambda_physics_values(N, options=options)\n",
    "print(lambda_physics_list)\n",
    "val_loss_list, train_LoKI_loss = [], []\n",
    "print_flag = 0\n",
    "\n",
    "#\n",
    "\"\"\"for lambda_physics_list in lambda_physics_list:\n",
    "\n",
    "    # 2. Get the best architecture\n",
    "    model_pinn_standard = (pinn_casadi.PhysicsAwareNet(base_architecture, lrn_rate , batch_size, 0, lambda_physics, activation_functions, W).to(device)).to(torch.double) \n",
    "\n",
    "    # 3. Train Model\n",
    "    myplot_pinn_standard = pinn_casadi.MyPlots()\n",
    "    data_prepocessed_copy = copy.deepcopy(data_prepocessed)\n",
    "    val_loader = torch.utils.data.DataLoader(data_prepocessed_copy.val_data, batch_size=batch_size, shuffle=True) # set to True\n",
    "\n",
    "    pinns_standard, epoch_loss_arr_train, epoch_loss_arr_val, best_seed_pinn, epoch_loss_train_physics_sanity  = pinn_casadi.getTrainedPinns(val_loader,data_prepocessed_copy, num_models, hidden_size_arr, lrn_rate, batch_size, 0, lambda_physics, activation_func, epoch_window,print_flag, ep_log_interval, myplot_pinn_standard, loss_func_data, loss_func_physics, training_threshold, max_epochs)\n",
    "\n",
    "    # 4. Append the value of the validation loss\n",
    "    val_loss_list.append(epoch_loss_arr_val[-1])\n",
    "    train_LoKI_loss.append(epoch_loss_train_physics_sanity[-1])\n",
    "\n",
    "#\n",
    "min_index = val_loss_list.index(min(val_loss_list))\n",
    "print(f\"Best lambda: {lambda_physics_list[min_index]}\")\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(5, 5), dpi=300)  \n",
    "plt.plot(np.array(lambda_physics_list)[:,0], val_loss_list, marker='o', label=r'$L_{VAL}$')\n",
    "plt.plot(np.array(lambda_physics_list)[:,0], train_LoKI_loss, marker='o', label=r'$L$(y, $y_{LoKI}$)')\n",
    "plt.xlabel(r'$\\lambda_{Physics}$')\n",
    "plt.ylabel(r'$Loss$')\n",
    "plt.legend()\n",
    "plt.show()\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pinn_casadi)\n",
    "import torch.nn.functional as F\n",
    "importlib.reload(dp)\n",
    "importlib.reload(plotter)\n",
    "\n",
    "# NEURAL NETWORK  ---------------------------------------------------------------------------------------------------------------------------------\n",
    "#PINN parameters\n",
    "#best_lambda_physics = lambda_physics_list[min_index]\n",
    "#print(\"Best lambda = \", best_lambda_physics)\n",
    "#lambda_physics =  best_lambda_physics    # [0.01036426, 0.53862728, 0.00301796] [0.03063382, 0.51784745, 0.0035539 ] # # L_1: pressure; L_2: current; L_3: zero charge - relative weigth \n",
    "lambda_physics = [0.01036426, 0.53862728, 0.00301796]\n",
    "lambda_physics = [0.0001036426, 0.0053862728, 0.0000301796]\n",
    "\n",
    "print_flag = 1\n",
    "\n",
    "# 2. Get the best architecture\n",
    "model_pinn_standard = (pinn_casadi.PhysicsAwareNet(base_architecture, lrn_rate , batch_size, 0, lambda_physics, activation_functions, W).to(device)).to(torch.double) \n",
    "\n",
    "# 3. Train Model\n",
    "myplot_pinn_standard = pinn_casadi.MyPlots()\n",
    "data_prepocessed_copy = copy.deepcopy(data_prepocessed)\n",
    "val_loader = torch.utils.data.DataLoader(data_prepocessed_copy.val_data, batch_size=batch_size, shuffle=True) # set to True\n",
    "\n",
    "#pinns_standard, epoch_loss_arr_train, epoch_loss_arr_val, best_seed_pinn, epoch_loss_train_physics_sanity  = pinn_casadi.getTrainedPinns(val_loader,data_prepocessed_copy, num_models, hidden_size_arr, lrn_rate, batch_size, 0, lambda_physics, activation_func, epoch_window,print_flag, ep_log_interval, myplot_pinn_standard, loss_func_data, loss_func_physics, training_threshold, max_epochs)\n",
    "pinns_standard, epoch_loss_arr_train, epoch_loss_arr_val, best_seed_pinn, epoch_loss_train_physics_sanity  = pinn_casadi.getTrainedPinns(val_loader,data_prepocessed_copy, 2, hidden_size_arr, lrn_rate, batch_size, 0, lambda_physics, activation_func, epoch_window,print_flag, ep_log_interval, myplot_pinn_standard, loss_func_data, loss_func_physics, training_threshold, max_epochs)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make copies to avoid modifying the value\n",
    "importlib.reload(plotter)\n",
    "importlib.reload(pinn_casadi)\n",
    "dataset_file_name = \"/Users/matildevalente/Documents/PINN_Paper/LTP_System/Datasets/Morris/p10/3input_300.txt\"\n",
    "\n",
    "# 2. Plot of the predicted vs target pressure, discharge current and electron density for the NN model and the Projection Model\n",
    "save_image_path = \"/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/compliance_with_physical_laws_NN/\"\n",
    "model_name = \"NN\"\n",
    "error_P_NN_before_proj, error_I_NN_before_proj, error_ne_NN_before_proj, error_P_NN_after_proj, error_I_NN_after_proj, error_ne_NN_after_proj=plotter.Pred_vs_Target_Laws_from_file(nn_models, data_prepocessed_copy, output, num_models, input, W, dataset_file_name, save_image_path, model_name)\n",
    "\n",
    "# 3. Plot of the predicted vs target pressure, discharge current and electron density for the Standard PINN model and the Projection Model\n",
    "save_image_path = \"/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/compliance_with_physical_laws_standard_PINN/\"\n",
    "model_name = \"Standard PINN\"\n",
    "error_P_standard_PINN_before_proj, error_I_standard_PINN_before_proj, error_ne_standard_PINN_before_proj, error_P_standard_PINN_after_proj, error_I_standard_PINN_after_proj, error_ne_standard_PINN_after_proj=plotter.Pred_vs_Target_Laws_from_file(pinns_standard, data_prepocessed_copy, output, num_models, input, W, dataset_file_name, save_image_path, model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Plot Loss Curve\n",
    "importlib.reload(plotter)\n",
    "path = '/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/model_training_loss_curves/'\n",
    "plotter.LossCurvePlotPINN(myplot_pinn_standard, path, \" \", num_models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **3.2. See Performance of Loss Based PINN and Compare it to Projection-Based PINN**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FUNCOES POR IMPLEMENTAR!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dp)\n",
    "importlib.reload(plotter)\n",
    "importlib.reload(pinn_casadi)\n",
    "\n",
    "# 1. Make copies to avoid modifying the value\n",
    "nn_models_safe = copy.deepcopy(nn_models)\n",
    "data_prepocessed_copy = copy.deepcopy(data_prepocessed)\n",
    "\n",
    "\n",
    "######## POR IMPLEMENTAR\n",
    "# 3. Plot of each output as a function of discharge current for a pressure of 2 Torr and a radius of the reactor of 12 mm \n",
    "path_plots_outputs = '/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/outputs_vs_current_single_P/'\n",
    "dataset_exp = '/Users/matildevalente/Documents/PINN_Paper/LTP_System/Datasets/ConstPressure/3input_40_3Torr.txt'\n",
    "#mean_rse_arr_NN, mean_rse_arr_PINN = plotter.Plot_Output_vs_Current_single_P(data_prepocessed_copy , dataset_exp, nn_models_safe, num_models, path_plots_outputs, log_y_scale = 0, constraint_func=pinn_casadi.compositeContraintFunc, W=torch.eye(17))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Barplots comparing errors when applying different constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pinn_casadi)\n",
    "importlib.reload(plotter)\n",
    "\n",
    "# 1. Extract experimental dataset\n",
    "file_name = \"/Users/matildevalente/Documents/PINN_Paper/LTP_System/Datasets/Morris/p10/3input_300.txt\"\n",
    "\n",
    "# 2. Path where the plots are to be stored\n",
    "save_path = \"/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/bar_plot_standard_PINN/\"\n",
    "\n",
    "# 3. Get results for identity matrix\n",
    "model_name = \"Standard PINN\"\n",
    "plotter.get_plot_W_matrix(torch.eye(17), file_name, data_prepocessed, pinns_standard, num_models, model_name, num_bars = 8, path = save_path)    \n",
    "plotter.get_plot_W_matrix(torch.eye(17), file_name, data_prepocessed, pinns_standard, num_models, model_name, num_bars = 5, path = save_path)    \n",
    "plotter.get_plot_W_matrix(torch.eye(17), file_name, data_prepocessed, pinns_standard, num_models, model_name, num_bars = 2, path = save_path)   \n",
    "model_name = \"NN\"\n",
    "plotter.get_plot_W_matrix(torch.eye(17), file_name, data_prepocessed, nn_models, num_models, model_name, num_bars = 2, path = save_path)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(plotter)\n",
    "\n",
    "############# PLOT DESCRIPTION #################\n",
    "save_path = \"/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/bar_plot_NN_and_standard_PINN/\"\n",
    "dataset_name = '/Users/matildevalente/Documents/PINN_Paper/LTP_System/Datasets/Morris/p10/3input_300.txt'\n",
    "RSE_proj_standard_PINN, RSE_not_proj_standard_PINN = plotter.get_plot_W_matrix_casadi(torch.eye(17), file_name, data_prepocessed, pinns_standard, num_models, num_bars = 2)    \n",
    "RSE_proj_NN, RSE_not_proj_NN = plotter.get_plot_W_matrix_casadi(np.eye(17), dataset_name, data_prepocessed_copy, nn_models, num_models, num_bars=2)\n",
    "\n",
    "plotter.PINN_NN_Proj_comparison(RSE_not_proj_standard_PINN, RSE_proj_standard_PINN, RSE_proj_NN, RSE_not_proj_NN, save_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compliance with physical laws analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make copies to avoid modifying the value\n",
    "importlib.reload(plotter)\n",
    "importlib.reload(pinn_casadi)\n",
    "dataset_file_name = \"/Users/matildevalente/Documents/PINN_Paper/LTP_System/Datasets/Morris/p10/3input_300.txt\"\n",
    "\n",
    "# 2. Plot of the predicted vs target pressure, discharge current and electron density for the NN model and the Projection Model\n",
    "save_image_path = \"/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/compliance_with_physical_laws_NN/\"\n",
    "model_name = \"NN\"\n",
    "error_P_NN_before_proj, error_I_NN_before_proj, error_ne_NN_before_proj, error_P_NN_after_proj, error_I_NN_after_proj, error_ne_NN_after_proj=plotter.Pred_vs_Target_Laws_from_file(nn_models, data_prepocessed_copy, output, num_models, input, W, dataset_file_name, save_image_path, model_name)\n",
    "\n",
    "# 3. Plot of the predicted vs target pressure, discharge current and electron density for the Standard PINN model and the Projection Model\n",
    "save_image_path = \"/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/compliance_with_physical_laws_standard_PINN/\"\n",
    "model_name = \"Standard PINN\"\n",
    "error_P_standard_PINN_before_proj, error_I_standard_PINN_before_proj, error_ne_standard_PINN_before_proj, error_P_standard_PINN_after_proj, error_I_standard_PINN_after_proj, error_ne_standard_PINN_after_proj=plotter.Pred_vs_Target_Laws_from_file(pinns_standard, data_prepocessed_copy, output, num_models, input, W, dataset_file_name, save_image_path, model_name)\n",
    "\n",
    "# Row names\n",
    "row_names = ['P Error', 'I Error', 'ne Error']\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'NN Model Before Projection ': [error_P_NN_before_proj, error_I_NN_before_proj, error_ne_NN_before_proj],\n",
    "    'NN Model After Projection': [error_P_NN_after_proj, error_I_NN_after_proj, error_ne_NN_after_proj],\n",
    "    'Loss Based Model Before Projection': [error_P_NN_after_proj, error_I_NN_after_proj, error_ne_NN_after_proj],\n",
    "    'Loss Based Model After Projection': [error_P_NN_after_proj, error_I_NN_after_proj, error_ne_NN_after_proj]\n",
    "}, index=row_names)\n",
    "\n",
    "# Display the DataFrame\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of the Pressure and Discharge Current Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(dp)\n",
    "importlib.reload(plotter)\n",
    "importlib.reload(pinn_casadi)\n",
    "\n",
    "# 1. Make copies to avoid modifying the value\n",
    "nn_models_safe = copy.deepcopy(nn_models)\n",
    "data_prepocessed_copy = copy.deepcopy(data_prepocessed)\n",
    "\n",
    "# 2. Plot of each output as a function of pressure for a discharge current of 30 mA and a radius of the reactor of 12 mm \n",
    "path_plots_outputs = '/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/outputs_vs_pressure_single_I/'\n",
    "dataset_exp = '/Users/matildevalente/Documents/PINN_Paper/LTP_System/Datasets/ConstCurrent/3input_50_30mA.txt'\n",
    "mean_rse_arr_NN, mean_rse_arr_PINN = plotter.Plot_Output_vs_Pressure_single_I(data_prepocessed_copy , dataset_exp, nn_models_safe, num_models, path_plots_outputs, log_y_scale = 0, constraint_func=pinn_casadi.compositeContraintFunc, W=torch.eye(17))\n",
    "\n",
    "# 5. Plot of each output as a function of pressure for discharge currents of 30, 50, and 70 mA and a radius of the reactor of 12 mm \n",
    "file_names = []\n",
    "currents = [10,20,30, 40]\n",
    "path_plots_outputs = '/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/outputs_vs_pressure_multiple_I/'\n",
    "for current in currents:\n",
    "    name = '/Users/matildevalente/Documents/PINN_Paper/LTP_System/Datasets/ConstCurrent/3input_50_'+str(current)+'mA.txt'\n",
    "    file_names.append(name)\n",
    "plotter.Plot_Output_vs_Pressure_multi_I(data_prepocessed_copy, file_names, nn_models_safe, num_models, path_plots_outputs)\n",
    "\n",
    "# 4. Plot of each output as a function of discharge current for pressures of 3, 5, and 7 Torr and a radius of the reactor of 12 mm \n",
    "file_names = []\n",
    "pressures = [3,5,7]\n",
    "path_plots_outputs = '/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/outputs_vs_current_multiple_P/'\n",
    "for pressure in pressures:\n",
    "    name = '/Users/matildevalente/Documents/PINN_Paper/LTP_System/Datasets/ConstPressure/3input_40_'+str(pressure)+'Torr.txt'\n",
    "    file_names.append(name)\n",
    "plotter.Plot_Output_vs_Current_multi_P(data_prepocessed_copy, file_names, nn_models_safe, num_models, path_plots_outputs, pinn_casadi.compositeContraintFunc, W, dont_apply_projection = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis of the best seed instead of aggregated model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"# 6. Similar to (2) but in the computation we use the best seed model instead of the average of seeds\n",
    "mean_rse_arr_NN, mean_rse_arr_PINN = plotter.Plot_Output_vs_Pressure_single(data_prepocessed_copy , dataset_exp, [best_seed_pinn], 1, path_plots_outputs, log_y_scale = 0, constraint_func=pinn_casadi.compositeContraintFunc, W=torch.eye(17))\n",
    "\n",
    "# 7. Similar to (3) but in the computation we use the best seed model instead of the average of seeds\n",
    "dataset_file_name = \"/Users/matildevalente/Documents/PINN_Paper/LTP_System/Datasets/Morris/p10/3input_300.txt\"\n",
    "save_path = \"/Users/matildevalente/Documents/PINN_Paper/LTP_System/Final_Plots/compliance_with_physical_laws_single_seed/\"\n",
    "plotter.Pred_vs_Target_Laws_from_file([best_seed_pinn], data_prepocessed_copy, output, 1, input, W, dataset_file_name, save_path)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
